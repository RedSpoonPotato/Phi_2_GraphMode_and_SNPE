{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 14:55:35.736354: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-05 14:55:36.266259: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-05 14:55:36.269416: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-05 14:55:37.650830: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = tf.float16 # subject to change\n",
    "BASE_DIR = \"/home/kernal1/QM_Sandbox/Phi_2/phi_local/weights/\"\n",
    "DECODER_LAYERS = 32\n",
    "DECODER_RANGE = [0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 14:55:40.540722: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-05 14:55:40.544137: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "# params['embed_tokens'] = tf.constant(np.load(BASE_DIR + 'embed_tokens.npy'), dtype=dtype)\n",
    "params['decoder_layers'] = dict()\n",
    "\n",
    "# for i in range(DECODER_LAYERS):\n",
    "for i in range(*DECODER_RANGE):\n",
    "  layer_params = {}\n",
    "  layer_params['layernorm_weight'] = 'layernorm_weight.npy'\n",
    "  layer_params['layernorm_bias'] = 'layernorm_bias'\n",
    "  layer_params['q_proj_weight'] = 'q_proj_weight'\n",
    "  layer_params['q_proj_bias'] = 'q_proj_bias'\n",
    "  layer_params['k_proj_weight'] = 'k_proj_weight'\n",
    "  layer_params['k_proj_bias'] = 'k_proj_bias'\n",
    "  layer_params['v_proj_weight'] = 'v_proj_weight'\n",
    "  layer_params['v_proj_bias'] = 'v_proj_bias'\n",
    "  layer_params['dense_weight'] = 'dense_weight'\n",
    "  layer_params['dense_bias'] = 'dense_bias'\n",
    "  layer_params['mlp_fc1_weight'] = 'mlp_fc1_weight'\n",
    "  layer_params['mlp_fc1_bias'] = 'mlp_fc1_bias'\n",
    "  layer_params['mlp_fc2_weight'] = 'mlp_fc2_weight'\n",
    "  layer_params['mlp_fc2_bias'] = 'mlp_fc2_bias'\n",
    "  for key in layer_params:\n",
    "    layer_params[key] = tf.constant(np.load(BASE_DIR + str(i) + '_' + key + '.npy'), dtype=dtype)\n",
    "    if \"weight\" in key and \"layernorm\" not in key:\n",
    "      layer_params[key] = tf.transpose(layer_params[key], perm=[1,0])\n",
    "    print(key, \": \", layer_params[key].shape) # remove later\n",
    "  # params['decoder_layers'].append(layer_params)\n",
    "  params['decoder_layers'][i] = layer_params\n",
    "\n",
    "params['final_layernorm_weight'] = tf.constant(np.load(BASE_DIR + 'final_layernorm_weight.npy'), dtype=dtype)\n",
    "params['final_layernorm_bias'] = tf.constant(np.load(BASE_DIR + 'final_layernorm_bias.npy'), dtype=dtype)\n",
    "\n",
    "params['lm_head_weight'] = tf.transpose(tf.constant(np.load(BASE_DIR + 'lm_head_weight.npy'), dtype=dtype), perm=[1,0])\n",
    "params['lm_head_bias'] = tf.constant(np.load(BASE_DIR + 'lm_head_bias.npy'), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhiConfig():\n",
    "    keys_to_ignore_at_inference = [\"past_key_values\"]\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size=51200,\n",
    "        hidden_size=2560,\n",
    "        intermediate_size=10240,\n",
    "        num_hidden_layers=DECODER_LAYERS, # modified,\n",
    "        num_attention_heads=32,\n",
    "        num_key_value_heads=32,\n",
    "        resid_pdrop=0.0, # the model bt default has 0.1 on colab, but we dont have randomness\n",
    "        embd_pdrop=0.0,\n",
    "        attention_dropout=0.0,\n",
    "        hidden_act=\"gelu_new\",\n",
    "        max_position_embeddings=2048,\n",
    "        initializer_range=0.00,\n",
    "        layer_norm_eps=1e-5,\n",
    "        use_cache=True,                  # Modifed\n",
    "        tie_word_embeddings=False,\n",
    "        rope_theta=10000.0,\n",
    "        rope_scaling=None,\n",
    "        partial_rotary_factor=0.4,\n",
    "        qk_layernorm=False,\n",
    "        bos_token_id=50256,\n",
    "        eos_token_id=50256,\n",
    "    ):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "\n",
    "        if num_key_value_heads is None:\n",
    "            num_key_value_heads = num_attention_heads\n",
    "\n",
    "        self.num_key_value_heads = num_key_value_heads\n",
    "        self.resid_pdrop = resid_pdrop\n",
    "        self.embd_pdrop = embd_pdrop\n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.hidden_act = hidden_act\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.initializer_range = initializer_range\n",
    "        self.layer_norm_eps = layer_norm_eps\n",
    "        self.use_cache = use_cache\n",
    "        self.rope_theta = rope_theta\n",
    "        self.rope_scaling = rope_scaling\n",
    "        self.partial_rotary_factor = partial_rotary_factor\n",
    "        self.qk_layernorm = qk_layernorm\n",
    "        self.pad_token_id = None\n",
    "        self._attn_implementation = 'eager'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upcasting from fp16 to fp32\n",
    "# for key in params:\n",
    "#     if (key != 'decoder_layers'):\n",
    "#         params[key] = tf.cast(params[key], dtype=tf.float32)\n",
    "\n",
    "# for index in params['decoder_layers']:\n",
    "#     for key in params['decoder_layers'][index]:\n",
    "#         params['decoder_layers'][index][key] = tf.cast(params['decoder_layers'][index][key], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PhiConfig(use_cache=True)\n",
    "import importlib\n",
    "\n",
    "import split_defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTensor(tensors:list, base_name:str, dir='.'):\n",
    "    for i in range(len(tensors)):\n",
    "        tensors[i].numpy().tofile(dir + \"/\" + base_name + \"_\" + str(i) + \".bin\")\n",
    "\n",
    "def saveTensorSingle(tensor:list, base_name:str, dir='.'):\n",
    "        tensor.numpy().tofile(dir + \"/\" + base_name + \".bin\")\n",
    "\n",
    "def loadTensor(path, shape:list, dtype):\n",
    "    with open(path, 'rb') as f:\n",
    "        tensor = np.fromfile(f, dtype=dtype)\n",
    "        tensor = tensor.reshape(shape)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for saving the layernorms\n",
    "# for i in range(*DECODER_RANGE):\n",
    "#     saveTensor((params['decoder_layers'][i]['layernorm_weight'],), 'layernorm_weight_' + str(i), \"data\")\n",
    "#     saveTensor((params['decoder_layers'][i]['layernorm_bias'],), 'layernorm_bias_' + str(i), \"data\")\n",
    "\n",
    "\n",
    "# assert(params['final_layernorm_weight'].dtype == tf.float32)\n",
    "# assert(params['final_layernorm_bias'].dtype == tf.float32)\n",
    "# assert(params['lm_head_weight'].dtype == tf.float32)\n",
    "# assert(params['lm_head_bias'].dtype == tf.float32)\n",
    "\n",
    "# saveTensorSingle(params['final_layernorm_weight'], \"final_layernorm_weight\", \"data\")\n",
    "# saveTensorSingle(params['final_layernorm_bias'], \"final_layernorm_bias\", \"data\")\n",
    "# saveTensorSingle(params['lm_head_weight'], \"lm_head_weight\", \"data\")\n",
    "# saveTensorSingle(params['lm_head_bias'], \"lm_head_bias\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing thing, ignore this block\n",
    "# one = 1\n",
    "# # TOT_SEQ_LEN = 11\n",
    "# importlib.reload(split_defs)\n",
    "# from split_defs import *\n",
    "# model_P3_not_first_reshaped = PhiDecodeP3_not_first_reshaped_test()\n",
    "# # tf.saved_model.save(model_P3_not_first_reshaped, \"tf/model_P3_not_first_reshaped_test\")\n",
    "# i1 = tf.random.uniform([1, 32, 2], dtype=tf.float32)\n",
    "# i2 = tf.random.uniform([1, 32, 80], dtype=tf.float32)\n",
    "# # saveTensor([i1, i2], \"P3_not_first_reshaped\", \"tf\")\n",
    "# model_P3_not_first_reshaped(i1, i2)['attn_output'].shape\n",
    "\n",
    "# SMALL_SIZE = 17\n",
    "# MEDIUM_SIZE = 23\n",
    "# params = {}\n",
    "# params['layernorm_weight'] = tf.random.uniform([SMALL_SIZE])\n",
    "# params['layernorm_bias'] = tf.random.uniform([SMALL_SIZE])\n",
    "# for char in ['q', 'k', 'v']:\n",
    "#     params[char + '_proj_weight'] = tf.random.uniform([SMALL_SIZE, SMALL_SIZE])\n",
    "#     params[char + '_proj_bias'] = tf.random.uniform([SMALL_SIZE])\n",
    "# params['mlp_fc1_weight'] = tf.random.uniform([SMALL_SIZE, MEDIUM_SIZE])\n",
    "# params['mlp_fc1_bias'] = tf.random.uniform([MEDIUM_SIZE])\n",
    "# params['mlp_fc2_weight'] = tf.random.uniform([MEDIUM_SIZE, SMALL_SIZE])\n",
    "# params['mlp_fc2_bias'] = tf.random.uniform([SMALL_SIZE])\n",
    "# config_test = config\n",
    "# config_test.hidden_size = SMALL_SIZE\n",
    "# config_test.intermediate_size = MEDIUM_SIZE\n",
    "\n",
    "# model_P1_reshaped_test = PhiDecodeP1_reshaped_test(config_test, params)\n",
    "# tf.saved_model.save(model_P1_reshaped_test, \"tf/model_P1_reshaped_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P2_reshaped/assets\n",
      "INFO:tensorflow:Assets written to: tf/model_P3_reshaped/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P3_reshaped/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'attn_output': <tf.Tensor: shape=(11, 32, 80), dtype=float32, numpy=\n",
       " array([[[3.5667095, 3.3553202, 3.962256 , ..., 3.6162434, 2.5772705,\n",
       "          2.766594 ],\n",
       "         [3.4241862, 2.9515045, 2.1299298, ..., 2.5272508, 3.7966962,\n",
       "          2.7136598],\n",
       "         [4.175536 , 4.624282 , 3.533833 , ..., 3.206243 , 4.4349113,\n",
       "          2.8653176],\n",
       "         ...,\n",
       "         [3.659787 , 2.750053 , 3.6893284, ..., 3.777901 , 3.3547568,\n",
       "          3.659802 ],\n",
       "         [1.9702328, 2.30117  , 1.8625683, ..., 2.6677506, 1.7995511,\n",
       "          2.07722  ],\n",
       "         [2.6265805, 2.9811764, 2.14341  , ..., 3.0121865, 3.561525 ,\n",
       "          3.7235084]],\n",
       " \n",
       "        [[4.2441087, 3.5411332, 3.4328122, ..., 3.3330834, 2.1473715,\n",
       "          4.0055513],\n",
       "         [3.403041 , 2.6335218, 2.474135 , ..., 2.1179957, 3.4421794,\n",
       "          3.0043902],\n",
       "         [3.187975 , 4.1446266, 2.883797 , ..., 2.6484537, 3.7617135,\n",
       "          1.8635944],\n",
       "         ...,\n",
       "         [2.0297165, 2.062406 , 2.0461736, ..., 2.2687285, 2.7863765,\n",
       "          2.281017 ],\n",
       "         [2.3150964, 2.2651105, 2.3167114, ..., 2.5430083, 1.9866179,\n",
       "          2.4223223],\n",
       "         [2.4767687, 3.3196862, 2.660852 , ..., 3.0151663, 3.4180264,\n",
       "          3.456701 ]],\n",
       " \n",
       "        [[3.538723 , 3.6103878, 3.710465 , ..., 2.9770005, 2.6510057,\n",
       "          3.9824142],\n",
       "         [3.561211 , 2.713674 , 2.7014046, ..., 2.8635838, 3.912915 ,\n",
       "          3.0240498],\n",
       "         [2.8250341, 3.2372725, 2.5762906, ..., 2.514755 , 3.1071272,\n",
       "          1.9709941],\n",
       "         ...,\n",
       "         [3.4899225, 2.776516 , 3.3700876, ..., 3.690511 , 3.5062656,\n",
       "          3.674034 ],\n",
       "         [1.9641308, 2.5758424, 1.8674941, ..., 2.878119 , 1.7781622,\n",
       "          2.1694887],\n",
       "         [1.2369956, 2.2011018, 1.5236582, ..., 1.9585541, 2.3117626,\n",
       "          2.3026214]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[3.0972195, 2.7943585, 2.8537014, ..., 2.5264294, 2.5628405,\n",
       "          3.1596956],\n",
       "         [3.926968 , 3.059575 , 2.668095 , ..., 2.2808962, 3.8698428,\n",
       "          2.926683 ],\n",
       "         [4.243155 , 4.5131617, 3.4735215, ..., 3.3237298, 4.820219 ,\n",
       "          2.7283936],\n",
       "         ...,\n",
       "         [3.3835497, 2.528456 , 3.7692535, ..., 2.8744304, 2.5005646,\n",
       "          2.6763625],\n",
       "         [2.179702 , 2.59379  , 2.1061063, ..., 3.252862 , 2.143351 ,\n",
       "          2.5295625],\n",
       "         [1.9232776, 3.1538234, 2.557154 , ..., 3.1379015, 3.096435 ,\n",
       "          3.314517 ]],\n",
       " \n",
       "        [[4.7000046, 3.5546308, 3.2686036, ..., 3.4005682, 2.9487877,\n",
       "          4.559778 ],\n",
       "         [1.8893101, 2.3179076, 1.6062082, ..., 1.2798967, 2.595671 ,\n",
       "          2.4109476],\n",
       "         [3.1160014, 2.9779022, 2.6374512, ..., 2.5717   , 3.427598 ,\n",
       "          2.234574 ],\n",
       "         ...,\n",
       "         [3.3115838, 2.6765647, 3.191077 , ..., 2.4008102, 2.739297 ,\n",
       "          2.6060834],\n",
       "         [2.5541596, 2.658507 , 2.8980074, ..., 3.7144885, 2.869937 ,\n",
       "          3.0032713],\n",
       "         [2.9318953, 3.896522 , 3.0670261, ..., 3.3503742, 4.041085 ,\n",
       "          4.123302 ]],\n",
       " \n",
       "        [[3.1068864, 2.051421 , 2.348663 , ..., 2.5669377, 2.4299817,\n",
       "          2.9391222],\n",
       "         [3.2369173, 3.1266026, 3.1791306, ..., 2.623805 , 4.0817313,\n",
       "          3.641718 ],\n",
       "         [3.863541 , 3.880067 , 3.3011808, ..., 3.1708548, 4.080499 ,\n",
       "          2.59617  ],\n",
       "         ...,\n",
       "         [2.9080312, 2.1580691, 3.4116645, ..., 2.4732013, 2.31139  ,\n",
       "          2.7026234],\n",
       "         [2.4422557, 2.939406 , 1.882625 , ..., 3.1287906, 2.1264932,\n",
       "          2.878897 ],\n",
       "         [2.5031116, 3.3587556, 2.8895645, ..., 3.4533806, 3.8574169,\n",
       "          3.2880583]]], dtype=float32)>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing each part\n",
    "importlib.reload(split_defs)\n",
    "from split_defs import *\n",
    "\n",
    "# model_gelu = NewGELU()\n",
    "# tf.saved_model.save(model_gelu, \"tf/model_gelu\")\n",
    "# i1 = tf.random.uniform([SEQ_LEN, INTERMEDIATE_SIZE], dtype=tf.float32)\n",
    "# saveTensor([i1], \"gelu\", \"tf\")\n",
    "# model_gelu(i1)\n",
    "\n",
    "# for i in range(DECODER_LAYERS):\n",
    "# for i in range(*DECODER_RANGE):\n",
    "    # model_P1_Q_reshaped = PhiDecodeP1_Q_reshaped_new_quant(params['decoder_layers'][i])\n",
    "    # tf.saved_model.save(model_P1_Q_reshaped, \"tf/model_P1_Q_reshaped_layer_\" + str(i))\n",
    "    # i1 = tf.random.uniform([SEQ_LEN, HIDDEN_SIZE], dtype=tf.float32)\n",
    "    # # saveTensor([i1], \"P1_Q_reshaped\", \"tf\")\n",
    "    # model_P1_Q_reshaped(i1)\n",
    "\n",
    "    # model_P1_K_reshaped = PhiDecodeP1_K_reshaped_new_quant(params['decoder_layers'][i])\n",
    "    # tf.saved_model.save(model_P1_K_reshaped, \"tf/model_P1_K_reshaped_layer_\" + str(i))\n",
    "    # i1 = tf.random.uniform([SEQ_LEN, HIDDEN_SIZE], dtype=tf.float32)\n",
    "    # # saveTensor([i1], \"P1_K_reshaped\", \"tf\")\n",
    "    # model_P1_K_reshaped(i1)\n",
    "\n",
    "    # model_P1_V_reshaped = PhiDecodeP1_V_reshaped_new_quant(params['decoder_layers'][i])\n",
    "    # tf.saved_model.save(model_P1_V_reshaped, \"tf/model_P1_V_reshaped_layer_\" + str(i))\n",
    "    # i1 = tf.random.uniform([SEQ_LEN, HIDDEN_SIZE], dtype=tf.float32)\n",
    "    # # saveTensor([i1], \"P1_V_reshaped\", \"tf\")\n",
    "    # model_P1_V_reshaped(i1)\n",
    "\n",
    "    # model_P1_FC1_reshaped = PhiDecodeP1_FC1_reshaped_new_quant(config, params['decoder_layers'][i])\n",
    "    # tf.saved_model.save(model_P1_FC1_reshaped, \"tf/model_P1_FC1_reshaped_layer_\" + str(i))\n",
    "    # i1 = tf.random.uniform([SEQ_LEN, HIDDEN_SIZE], dtype=tf.float32)\n",
    "    # # saveTensor([i1], \"P1_FC1_reshaped\", \"tf\")\n",
    "    # model_P1_FC1_reshaped(i1)\n",
    "\n",
    "    # model_P1_2_reshaped = PhiDecodeP1_2_reshaped_new_quant(config, params['decoder_layers'][i])\n",
    "    # tf.saved_model.save(model_P1_2_reshaped, \"tf/model_P1_2_reshaped_layer_\" + str(i))\n",
    "    # i1 = tf.random.uniform([SEQ_LEN, INTERMEDIATE_SIZE], dtype=tf.float32)\n",
    "    # saveTensor([i1], \"P1_2_reshaped\", \"tf\")\n",
    "    # model_P1_2_reshaped(i1)\n",
    "\n",
    "# model_P2_1_first_buffered = PhiDecodeP2_1_first_buffered_unquant_fp32(config)\n",
    "# # tf.saved_model.save(model_P2_1_first_buffered, \"tf/model_P2_1_first_buffered\")\n",
    "# i1 = tf.random.uniform([32, MAX_SEQ_LEN, 80], dtype=tf.float32)\n",
    "# i2 = tf.random.uniform([32, MAX_SEQ_LEN, 80], dtype=tf.float32)\n",
    "# i3 = tf.random.uniform([MAX_SEQ_LEN, MAX_SEQ_LEN], dtype=tf.float32)\n",
    "# # saveTensor([i1, i2, i3], \"P2_1_first_buffered\", \"tf\")\n",
    "# model_P2_1_first_buffered(i1, i2, i3)\n",
    "\n",
    "# model_P2_not_first_reshaped = PhiDecodeP2_not_first_reshaped_unquant_fp32(config)\n",
    "# # tf.saved_model.save(model_P2_not_first_reshaped, \"tf/model_P2_not_first_reshaped\")\n",
    "# i1 = tf.random.uniform([SEQ_LEN, 32, 80], dtype=tf.float32)\n",
    "# i2 = tf.random.uniform([TOT_SEQ_LEN, 32, 80], dtype=tf.float32)\n",
    "# i3 = tf.random.uniform([TOT_SEQ_LEN], dtype=tf.float32)\n",
    "# # saveTensor([i1, i2, i3], \"P2_not_first_reshaped\", \"tf\")\n",
    "# model_P2_not_first_reshaped(i1, i2, i3)\n",
    "\n",
    "# model_P2_not_first_reshaped = PhiDecodeP2_not_first_reshaped_unquant_fp32(config)\n",
    "# # tf.saved_model.save(model_P2_not_first_reshaped, \"tf/model_P2_not_first_reshaped\")\n",
    "# i1 = tf.random.uniform([SEQ_LEN, 32, 80], dtype=tf.float32)\n",
    "# i2 = tf.random.uniform([TOT_SEQ_LEN, 32, 80], dtype=tf.float32)\n",
    "# # saveTensor([i1, i2], \"P2_not_first_reshaped\", \"tf\")\n",
    "# model_P2_not_first_reshaped(i1, i2)\n",
    "\n",
    "model_P2_reshaped = PhiDecodeP2_reshaped_unquant_fp32(config)\n",
    "tf.saved_model.save(model_P2_reshaped, \"tf/model_P2_reshaped\")\n",
    "i1 = tf.random.uniform([32, SEQ_LEN, 80], dtype=tf.float32)\n",
    "i2 = tf.random.uniform([32, TOT_SEQ_LEN, 80], dtype=tf.float32)\n",
    "# saveTensor([i1, i2], \"P2_reshaped\", \"tf\")\n",
    "model_P2_reshaped(i1, i2)\n",
    "\n",
    "# model_P3_not_first_reshaped = PhiDecodeP3_not_first_reshaped_quant_alt()\n",
    "# tf.saved_model.save(model_P3_not_first_reshaped, \"tf/model_P3_not_first_reshaped\")\n",
    "# i1 = tf.random.uniform([32, 1, SEQ_LEN], dtype=tf.float32)\n",
    "# i2 = tf.random.uniform([32, SEQ_LEN, 80], dtype=tf.float32)\n",
    "# saveTensor([i1, i2], \"P2_not_first_reshaped\", \"tf\")\n",
    "# model_P3_not_first_reshaped(i1, i2)\n",
    "\n",
    "model_P3_reshaped = PhiDecodeP3_reshaped_quant()\n",
    "tf.saved_model.save(model_P3_reshaped, \"tf/model_P3_reshaped\")\n",
    "i1 = tf.random.uniform([32, SEQ_LEN, TOT_SEQ_LEN], dtype=tf.float32)\n",
    "i2 = tf.random.uniform([32, TOT_SEQ_LEN, 80], dtype=tf.float32)\n",
    "# saveTensor([i1, i2], \"P3_reshaped\", \"tf\")\n",
    "model_P3_reshaped(i1, i2)\n",
    "\n",
    "# model_P3_first_buffered = PhiDecodeP3_first_buffered_quant()\n",
    "# tf.saved_model.save(model_P3_first_buffered, \"tf/model_P3_first_buffered\")\n",
    "# i1 = tf.random.uniform([32, MAX_SEQ_LEN, MAX_SEQ_LEN], dtype=tf.float32)\n",
    "# i2 = tf.random.uniform([32, MAX_SEQ_LEN, 80], dtype=tf.float32)\n",
    "# saveTensor([i1, i2], \"P3_first_buffered\", \"tf\")\n",
    "# i1 = loadTensor(\"/home/kernal1/QM_Sandbox/htp/order66/value_states.bin\", [32, MAX_SEQ_LEN, 80], np.float32)\n",
    "# i2 = loadTensor(\"/home/kernal1/QM_Sandbox/htp/order66/attn_weights.bin\", [32, MAX_SEQ_LEN, MAX_SEQ_LEN], np.float32)\n",
    "# print(i1)\n",
    "# print(i2)\n",
    "# print(model_P3_first_buffered(i1, i2))\n",
    "\n",
    "# model_P3_not_first_reshaped = PhiDecodeP3_not_first_reshaped_quant()\n",
    "# # tf.saved_model.save(model_P3_not_first_reshaped, \"tf/model_P3_not_first_reshaped\")\n",
    "# i1 = tf.random.uniform([TOT_SEQ_LEN, 32, one], dtype=tf.float32)\n",
    "# i2 = tf.random.uniform([TOT_SEQ_LEN, 32, 80], dtype=tf.float32)\n",
    "# # saveTensor([i1, i2], \"P3_not_first_reshaped\", \"tf\")\n",
    "# model_P3_not_first_reshaped(i1, i2)['attn_output'].shape\n",
    "\n",
    "# model_P3_not_first_buffered = PhiDecodeP3_not_first_buffered_quant()\n",
    "# # tf.saved_model.save(model_P3_not_first_buffered, \"tf/model_P3_not_first_buffered\")\n",
    "# i1 = tf.random.uniform([32, one, MAX_SEQ_LEN], dtype=tf.float32)\n",
    "# i2 = tf.random.uniform([32, MAX_SEQ_LEN, 80], dtype=tf.float32)\n",
    "# # saveTensor([i1, i2], \"P3_not_first_buffered\", \"tf\")\n",
    "# model_P3_not_first_buffered(i1, i2)['attn_output'].shape\n",
    "\n",
    "# for i in range(DECODER_LAYERS):\n",
    "# for i in range(*DECODER_RANGE):\n",
    "    # model_P4_1_reshaped = PhiDecodeP4_1_reshaped_quant(params['decoder_layers'][i], config)\n",
    "    # tf.saved_model.save(model_P4_1_reshaped, \"tf/model_P4_1_reshaped_layer_\" + str(i))\n",
    "    # i1 = tf.random.uniform([SEQ_LEN, HIDDEN_SIZE], dtype=tf.float32)\n",
    "    # saveTensor([i1], \"P4_1_reshaped\", \"tf\")\n",
    "    # model_P4_1_reshaped(i1)\n",
    "\n",
    "# model_P4_2_reshaped = PhiDecodeP4_2_reshaped_unquant(config)\n",
    "# # tf.saved_model.save(model_P4_2_reshaped, \"tf/model_P4_2_reshaped\")\n",
    "# i1 = tf.random.uniform([SEQ_LEN, HIDDEN_SIZE], dtype=tf.float32)\n",
    "# i2 = tf.random.uniform([SEQ_LEN, HIDDEN_SIZE], dtype=tf.float32)\n",
    "# i3 = tf.random.uniform([SEQ_LEN, HIDDEN_SIZE], dtype=tf.float32)\n",
    "# # saveTensor([i1, i2, i3], \"P4_2_reshaped\", \"tf\")\n",
    "# model_P4_2_reshaped(i1, i2, i3)\n",
    "\n",
    "# model_Final_LM_Head = PhiFinalLMHead_quant(params, config)\n",
    "# tf.saved_model.save(model_Final_LM_Head, \"tf/model_Final_LM_Head\")\n",
    "# i1 = tf.random.uniform([SEQ_LEN, HIDDEN_SIZE], dtype=tf.float32)\n",
    "# model_Final_LM_Head(i1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
