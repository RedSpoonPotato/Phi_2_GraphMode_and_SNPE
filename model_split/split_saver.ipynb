{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 21:13:55.778026: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-31 21:13:55.817058: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-31 21:13:55.817607: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-31 21:13:56.529962: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dtype = tf.float16 # subject to change\n",
    "BASE_DIR = \"/home/kernal1/QM_Sandbox/Phi_2/phi_local/weights/\"\n",
    "# DECODER_LAYERS = 3 # PUT BACK IN\n",
    "DECODER_LAYERS = 3  # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 21:13:57.786041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-31 21:13:57.786465: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layernorm_weight :  (2560,)\n",
      "layernorm_bias :  (2560,)\n",
      "q_proj_weight :  (2560, 2560)\n",
      "q_proj_bias :  (2560,)\n",
      "k_proj_weight :  (2560, 2560)\n",
      "k_proj_bias :  (2560,)\n",
      "v_proj_weight :  (2560, 2560)\n",
      "v_proj_bias :  (2560,)\n",
      "dense_weight :  (2560, 2560)\n",
      "dense_bias :  (2560,)\n",
      "mlp_fc1_weight :  (2560, 10240)\n",
      "mlp_fc1_bias :  (10240,)\n",
      "mlp_fc2_weight :  (10240, 2560)\n",
      "mlp_fc2_bias :  (2560,)\n",
      "layernorm_weight :  (2560,)\n",
      "layernorm_bias :  (2560,)\n",
      "q_proj_weight :  (2560, 2560)\n",
      "q_proj_bias :  (2560,)\n",
      "k_proj_weight :  (2560, 2560)\n",
      "k_proj_bias :  (2560,)\n",
      "v_proj_weight :  (2560, 2560)\n",
      "v_proj_bias :  (2560,)\n",
      "dense_weight :  (2560, 2560)\n",
      "dense_bias :  (2560,)\n",
      "mlp_fc1_weight :  (2560, 10240)\n",
      "mlp_fc1_bias :  (10240,)\n",
      "mlp_fc2_weight :  (10240, 2560)\n",
      "mlp_fc2_bias :  (2560,)\n",
      "layernorm_weight :  (2560,)\n",
      "layernorm_bias :  (2560,)\n",
      "q_proj_weight :  (2560, 2560)\n",
      "q_proj_bias :  (2560,)\n",
      "k_proj_weight :  (2560, 2560)\n",
      "k_proj_bias :  (2560,)\n",
      "v_proj_weight :  (2560, 2560)\n",
      "v_proj_bias :  (2560,)\n",
      "dense_weight :  (2560, 2560)\n",
      "dense_bias :  (2560,)\n",
      "mlp_fc1_weight :  (2560, 10240)\n",
      "mlp_fc1_bias :  (10240,)\n",
      "mlp_fc2_weight :  (10240, 2560)\n",
      "mlp_fc2_bias :  (2560,)\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params['embed_tokens'] = tf.constant(np.load(BASE_DIR + 'embed_tokens.npy'), dtype=dtype)\n",
    "params['decoder_layers'] = []\n",
    "\n",
    "for i in range(DECODER_LAYERS):\n",
    "  layer_params = {}\n",
    "  layer_params['layernorm_weight'] = 'layernorm_weight.npy'\n",
    "  layer_params['layernorm_bias'] = 'layernorm_bias'\n",
    "  layer_params['q_proj_weight'] = 'q_proj_weight'\n",
    "  layer_params['q_proj_bias'] = 'q_proj_bias'\n",
    "  layer_params['k_proj_weight'] = 'k_proj_weight'\n",
    "  layer_params['k_proj_bias'] = 'k_proj_bias'\n",
    "  layer_params['v_proj_weight'] = 'v_proj_weight'\n",
    "  layer_params['v_proj_bias'] = 'v_proj_bias'\n",
    "  layer_params['dense_weight'] = 'dense_weight'\n",
    "  layer_params['dense_bias'] = 'dense_bias'\n",
    "  layer_params['mlp_fc1_weight'] = 'mlp_fc1_weight'\n",
    "  layer_params['mlp_fc1_bias'] = 'mlp_fc1_bias'\n",
    "  layer_params['mlp_fc2_weight'] = 'mlp_fc2_weight'\n",
    "  layer_params['mlp_fc2_bias'] = 'mlp_fc2_bias'\n",
    "  for key in layer_params:\n",
    "    layer_params[key] = tf.constant(np.load(BASE_DIR + str(i) + '_' + key + '.npy'), dtype=dtype)\n",
    "    if \"weight\" in key and \"layernorm\" not in key:\n",
    "      layer_params[key] = tf.transpose(layer_params[key], perm=[1,0])\n",
    "    print(key, \": \", layer_params[key].shape) # remove later\n",
    "  params['decoder_layers'].append(layer_params)\n",
    "\n",
    "params['final_layernorm_weight'] = tf.constant(np.load(BASE_DIR + 'final_layernorm_weight.npy'), dtype=dtype)\n",
    "params['final_layernorm_bias'] = tf.constant(np.load(BASE_DIR + 'final_layernorm_bias.npy'), dtype=dtype)\n",
    "\n",
    "params['lm_head_weight'] = tf.transpose(tf.constant(np.load(BASE_DIR + 'lm_head_weight.npy'), dtype=dtype), perm=[1,0])\n",
    "params['lm_head_bias'] = tf.constant(np.load(BASE_DIR + 'lm_head_bias.npy'), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhiConfig():\n",
    "    keys_to_ignore_at_inference = [\"past_key_values\"]\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size=51200,\n",
    "        hidden_size=2560,\n",
    "        intermediate_size=10240,\n",
    "        num_hidden_layers=DECODER_LAYERS, # modified,\n",
    "        num_attention_heads=32,\n",
    "        num_key_value_heads=32,\n",
    "        resid_pdrop=0.0, # the model bt default has 0.1 on colab, but we dont have randomness\n",
    "        embd_pdrop=0.0,\n",
    "        attention_dropout=0.0,\n",
    "        hidden_act=\"gelu_new\",\n",
    "        max_position_embeddings=2048,\n",
    "        initializer_range=0.00,\n",
    "        layer_norm_eps=1e-5,\n",
    "        use_cache=True,                  # Modifed\n",
    "        tie_word_embeddings=False,\n",
    "        rope_theta=10000.0,\n",
    "        rope_scaling=None,\n",
    "        partial_rotary_factor=0.4,\n",
    "        qk_layernorm=False,\n",
    "        bos_token_id=50256,\n",
    "        eos_token_id=50256,\n",
    "    ):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "\n",
    "        if num_key_value_heads is None:\n",
    "            num_key_value_heads = num_attention_heads\n",
    "\n",
    "        self.num_key_value_heads = num_key_value_heads\n",
    "        self.resid_pdrop = resid_pdrop\n",
    "        self.embd_pdrop = embd_pdrop\n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.hidden_act = hidden_act\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.initializer_range = initializer_range\n",
    "        self.layer_norm_eps = layer_norm_eps\n",
    "        self.use_cache = use_cache\n",
    "        self.rope_theta = rope_theta\n",
    "        self.rope_scaling = rope_scaling\n",
    "        self.partial_rotary_factor = partial_rotary_factor\n",
    "        self.qk_layernorm = qk_layernorm\n",
    "        self.pad_token_id = None\n",
    "        self._attn_implementation = 'eager'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_tokens\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "decoder_layers\n",
      "<class 'list'>\n",
      "final_layernorm_weight\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "final_layernorm_bias\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "lm_head_weight\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "lm_head_bias\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "# upcasting from fp16 to fp32\n",
    "for d in params:\n",
    "    print(d)\n",
    "    print(type(params[d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upcasting from fp16 to fp32\n",
    "for key in params:\n",
    "    if (key != 'decoder_layers'):\n",
    "        params[key] = tf.cast(params[key], dtype=tf.float32)\n",
    "\n",
    "for weights in params['decoder_layers']:\n",
    "    for key in weights:\n",
    "        weights[key] = tf.cast(weights[key], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PhiConfig(use_cache=True)\n",
    "import importlib\n",
    "\n",
    "import split_defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTensor(tensors:list, base_name:str, dir='.'):\n",
    "    for i in range(len(tensors)):\n",
    "        tensors[i].numpy().tofile(dir + \"/\" + base_name + \"_\" + str(i) + \".bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P1_reshaped_test/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P1_reshaped_test/assets\n"
     ]
    }
   ],
   "source": [
    "# testing thing, ignore this block\n",
    "one = 1\n",
    "# TOT_SEQ_LEN = 11\n",
    "importlib.reload(split_defs)\n",
    "from split_defs import *\n",
    "model_P3_not_first_reshaped = PhiDecodeP3_not_first_reshaped_test()\n",
    "# tf.saved_model.save(model_P3_not_first_reshaped, \"tf/model_P3_not_first_reshaped_test\")\n",
    "i1 = tf.random.uniform([1, 32, 2], dtype=tf.float32)\n",
    "i2 = tf.random.uniform([1, 32, 80], dtype=tf.float32)\n",
    "# saveTensor([i1, i2], \"P3_not_first_reshaped\", \"tf\")\n",
    "model_P3_not_first_reshaped(i1, i2)['attn_output'].shape\n",
    "\n",
    "SMALL_SIZE = 17\n",
    "MEDIUM_SIZE = 23\n",
    "params = {}\n",
    "params['layernorm_weight'] = tf.random.uniform([SMALL_SIZE])\n",
    "params['layernorm_bias'] = tf.random.uniform([SMALL_SIZE])\n",
    "for char in ['q', 'k', 'v']:\n",
    "    params[char + '_proj_weight'] = tf.random.uniform([SMALL_SIZE, SMALL_SIZE])\n",
    "    params[char + '_proj_bias'] = tf.random.uniform([SMALL_SIZE])\n",
    "params['mlp_fc1_weight'] = tf.random.uniform([SMALL_SIZE, MEDIUM_SIZE])\n",
    "params['mlp_fc1_bias'] = tf.random.uniform([MEDIUM_SIZE])\n",
    "params['mlp_fc2_weight'] = tf.random.uniform([MEDIUM_SIZE, SMALL_SIZE])\n",
    "params['mlp_fc2_bias'] = tf.random.uniform([SMALL_SIZE])\n",
    "config_test = config\n",
    "config_test.hidden_size = SMALL_SIZE\n",
    "config_test.intermediate_size = MEDIUM_SIZE\n",
    "\n",
    "model_P1_reshaped_test = PhiDecodeP1_reshaped_test(config_test, params)\n",
    "tf.saved_model.save(model_P1_reshaped_test, \"tf/model_P1_reshaped_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0.00344086 -0.0015564   0.01211548 ... -0.00995636 -0.00195312\n",
      "  0.00417709], shape=(2560,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"decoder_layers\"][0]['mlp_fc2_bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P1_1_reshaped_layer_0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P1_1_reshaped_layer_0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P1_2_reshaped_layer_0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P1_2_reshaped_layer_0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P1_1_reshaped_layer_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P1_1_reshaped_layer_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P1_2_reshaped_layer_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P1_2_reshaped_layer_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P1_1_reshaped_layer_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P1_1_reshaped_layer_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P1_2_reshaped_layer_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P1_2_reshaped_layer_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P4_1_reshaped_layer_0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P4_1_reshaped_layer_0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P4_1_reshaped_layer_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P4_1_reshaped_layer_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P4_1_reshaped_layer_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf/model_P4_1_reshaped_layer_2/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'decoder_output': <tf.Tensor: shape=(11, 2560), dtype=float32, numpy=\n",
       " array([[1.1600487 , 1.1147425 , 1.5496042 , ..., 1.1009688 , 1.3456794 ,\n",
       "         1.2850387 ],\n",
       "        [2.0780468 , 1.2212307 , 1.0555482 , ..., 2.0447173 , 2.0029273 ,\n",
       "         2.2573972 ],\n",
       "        [2.0480623 , 1.258871  , 1.6186678 , ..., 1.3265406 , 1.7750793 ,\n",
       "         1.0666127 ],\n",
       "        ...,\n",
       "        [1.982787  , 1.5928941 , 1.5564563 , ..., 0.9943732 , 1.0433061 ,\n",
       "         1.101676  ],\n",
       "        [2.5243711 , 2.5334134 , 1.0764894 , ..., 1.8100047 , 0.6865206 ,\n",
       "         1.2755989 ],\n",
       "        [1.432938  , 1.6635695 , 1.4438607 , ..., 0.6990149 , 0.70277023,\n",
       "         2.1240625 ]], dtype=float32)>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing each part\n",
    "importlib.reload(split_defs)\n",
    "from split_defs import *\n",
    "\n",
    "model_gelu = NewGELU()\n",
    "# tf.saved_model.save(model_gelu, \"tf/model_gelu\")\n",
    "i1 = tf.random.uniform([SEQ_LEN, INTERMEDIATE_SIZE], dtype=tf.float32)\n",
    "# saveTensor([i1], \"gelu\", \"tf\")\n",
    "model_gelu(i1)\n",
    "\n",
    "for i in range(DECODER_LAYERS):\n",
    "    model_P1_1_reshaped = PhiDecodeP1_1_reshaped_new_quant(config, params['decoder_layers'][i])\n",
    "    tf.saved_model.save(model_P1_1_reshaped, \"tf/model_P1_1_reshaped_layer_\" + str(i))\n",
    "    i1 = tf.random.uniform([SEQ_LEN, HIDDEN_SIZE], dtype=tf.float32)\n",
    "    # saveTensor([i1], \"P1_1_reshaped\", \"tf\")\n",
    "    model_P1_1_reshaped(i1)\n",
    "\n",
    "    model_P1_2_reshaped = PhiDecodeP1_2_reshaped_new_quant(config, params['decoder_layers'][i])\n",
    "    tf.saved_model.save(model_P1_2_reshaped, \"tf/model_P1_2_reshaped_layer_\" + str(i))\n",
    "    i1 = tf.random.uniform([SEQ_LEN, INTERMEDIATE_SIZE], dtype=tf.float32)\n",
    "    # saveTensor([i1], \"P1_2_reshaped\", \"tf\")\n",
    "    model_P1_2_reshaped(i1)\n",
    "\n",
    "model_P2_1_first_buffered = PhiDecodeP2_1_first_buffered_unquant_fp32(config)\n",
    "# tf.saved_model.save(model_P2_1_first_buffered, \"tf/model_P2_1_first_buffered\")\n",
    "i1 = tf.random.uniform([32, MAX_SEQ_LEN, 80], dtype=tf.float32)\n",
    "i2 = tf.random.uniform([32, MAX_SEQ_LEN, 80], dtype=tf.float32)\n",
    "i3 = tf.random.uniform([MAX_SEQ_LEN, MAX_SEQ_LEN], dtype=tf.float32)\n",
    "# saveTensor([i1, i2, i3], \"P2_1_first_buffered\", \"tf\")\n",
    "model_P2_1_first_buffered(i1, i2, i3)\n",
    "\n",
    "model_P2_not_first_reshaped = PhiDecodeP2_not_first_reshaped_unquant_fp32(config)\n",
    "# tf.saved_model.save(model_P2_not_first_reshaped, \"tf/model_P2_not_first_reshaped\")\n",
    "i1 = tf.random.uniform([SEQ_LEN, 32, 80], dtype=tf.float32)\n",
    "i2 = tf.random.uniform([TOT_SEQ_LEN, 32, 80], dtype=tf.float32)\n",
    "i3 = tf.random.uniform([TOT_SEQ_LEN], dtype=tf.float32)\n",
    "# saveTensor([i1, i2, i3], \"P2_not_first_reshaped\", \"tf\")\n",
    "model_P2_not_first_reshaped(i1, i2, i3)\n",
    "\n",
    "model_P3_first_buffered = PhiDecodeP3_first_buffered_quant()\n",
    "# tf.saved_model.save(model_P3_first_buffered, \"tf/model_P3_first_buffered\")\n",
    "i1 = tf.random.uniform([MAX_SEQ_LEN, 32, 80], dtype=tf.float32)\n",
    "i2 = tf.random.uniform([32, MAX_SEQ_LEN, MAX_SEQ_LEN], dtype=tf.float32) \n",
    "# saveTensor([i1, i2], \"P3_first_buffered\", \"tf\")\n",
    "model_P3_first_buffered(i1, i2)\n",
    "\n",
    "model_P3_not_first_reshaped = PhiDecodeP3_not_first_reshaped_quant()\n",
    "# tf.saved_model.save(model_P3_not_first_reshaped, \"tf/model_P3_not_first_reshaped\")\n",
    "i1 = tf.random.uniform([TOT_SEQ_LEN, 32, one], dtype=tf.float32)\n",
    "i2 = tf.random.uniform([TOT_SEQ_LEN, 32, 80], dtype=tf.float32)\n",
    "# saveTensor([i1, i2], \"P3_not_first_reshaped\", \"tf\")\n",
    "model_P3_not_first_reshaped(i1, i2)['attn_output'].shape\n",
    "\n",
    "model_P3_not_first_buffered = PhiDecodeP3_not_first_buffered_quant()\n",
    "# tf.saved_model.save(model_P3_not_first_buffered, \"tf/model_P3_not_first_buffered\")\n",
    "i1 = tf.random.uniform([32, one, MAX_SEQ_LEN], dtype=tf.float32)\n",
    "i2 = tf.random.uniform([32, MAX_SEQ_LEN, 80], dtype=tf.float32)\n",
    "# saveTensor([i1, i2], \"P3_not_first_buffered\", \"tf\")\n",
    "model_P3_not_first_buffered(i1, i2)['attn_output'].shape\n",
    "\n",
    "for i in range(DECODER_LAYERS):\n",
    "    model_P4_1_reshaped = PhiDecodeP4_1_reshaped_quant(params['decoder_layers'][i], config)\n",
    "    tf.saved_model.save(model_P4_1_reshaped, \"tf/model_P4_1_reshaped_layer_\" + str(i))\n",
    "    i1 = tf.random.uniform([SEQ_LEN, HIDDEN_SIZE], dtype=tf.float32)\n",
    "    # saveTensor([i1, i2, i3], \"P4_1_reshaped\", \"tf\")\n",
    "    model_P4_1_reshaped(i1)\n",
    "\n",
    "model_P4_2_reshaped = PhiDecodeP4_2_reshaped_unquant(config)\n",
    "# tf.saved_model.save(model_P4_2_reshaped, \"tf/model_P4_2_reshaped\")\n",
    "i1 = tf.random.uniform([SEQ_LEN, HIDDEN_SIZE], dtype=tf.float32)\n",
    "i2 = tf.random.uniform([SEQ_LEN, HIDDEN_SIZE], dtype=tf.float32)\n",
    "i3 = tf.random.uniform([SEQ_LEN, HIDDEN_SIZE], dtype=tf.float32)\n",
    "# saveTensor([i1, i2, i3], \"P4_2_reshaped\", \"tf\")\n",
    "model_P4_2_reshaped(i1, i2, i3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
